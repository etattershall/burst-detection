{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning pipeline\n",
    "\n",
    "This notebook takes a dataset separated out by year into the format\n",
    "\n",
    "- 1975.csv\n",
    "- 1976.csv\n",
    "- 1977.csv\n",
    "\n",
    "etc, and transforms it into a set of dataframes of clean text that can be stored in a series of p files containing only the document id and cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../tools\")\n",
    "import my_stopwords\n",
    "import my_parameters\n",
    "import cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = my_stopwords.get_stopwords()\n",
    "parameters = my_parameters.set_parameters()\n",
    "\n",
    "dataset_name = 'dblp_cs'\n",
    "raw_data_path = 'Raw_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988 6906\n",
      "1989 7947\n",
      "1990 9328\n",
      "1991 10599\n",
      "1992 12985\n",
      "1993 15213\n",
      "1994 18756\n",
      "1995 20607\n",
      "1996 24408\n",
      "1997 27865\n",
      "1998 32629\n",
      "1999 35897\n",
      "2000 42482\n",
      "2001 45158\n",
      "2002 52898\n",
      "2003 64871\n",
      "2004 90084\n",
      "2005 105201\n",
      "2006 120579\n",
      "2007 132013\n",
      "2008 141659\n",
      "2009 152864\n",
      "2010 161380\n",
      "2011 173486\n",
      "2012 183729\n",
      "2013 189858\n",
      "2014 195136\n",
      "2015 195426\n",
      "2016 197102\n",
      "2017 188640\n"
     ]
    }
   ],
   "source": [
    "cleaner = cleaning.Clean(parameters[\"ngram_length\"])\n",
    "\n",
    "for year in range(1988,2018):\n",
    "    df = pd.read_csv(raw_data_path+str(year)+'.csv')\n",
    "    print(year, len(df))\n",
    "    \n",
    "    cleaned_text = []\n",
    "    cleaned_df = pd.DataFrame()\n",
    "    \n",
    "    if 'language' in df.keys():\n",
    "        for index, row in df[df['language']=='en'].iterrows():\n",
    "            cleaned_text.append(cleaner.cleaning_pipeline(row['title'], row['abstract'], pad=False))\n",
    "            \n",
    "        cleaned_df['id'] = list(df[df['language']=='en'].ssid)\n",
    "    else:\n",
    "        for index, row in df.iterrows():\n",
    "            cleaned_text.append(cleaner.cleaning_pipeline(row['title'], row['abstract'], pad=False))\n",
    "            \n",
    "        cleaned_df['id'] = list(df.ssid)\n",
    "        \n",
    "    cleaned_df['cleaned'] = cleaned_text\n",
    "    \n",
    "    pickle.dump(cleaned_df, open(\"dataset_name+\"/\"+str(year)+\".p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
